# AI Configuration for D&D Character Consultant System
# Copy this file to .env and fill in your configuration

# ============================================================================
# OpenAI Configuration (default)
# ============================================================================
# Get your API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=your-openai-api-key-here
# OPENAI_BASE_URL=  # Leave empty for default OpenAI
# OPENAI_MODEL=gpt-3.5-turbo  # or gpt-4, gpt-4-turbo, etc.

# ============================================================================
# Ollama Configuration (local LLMs)
# ============================================================================
# If using Ollama (local), uncomment and configure:
# OPENAI_API_KEY=ollama  # Ollama doesn't need a real key
# OPENAI_BASE_URL=http://localhost:11434/v1
# OPENAI_MODEL=llama3.2  # or mistral, mixtral, etc.

# ============================================================================
# OpenRouter Configuration (multiple providers)
# ============================================================================
# If using OpenRouter, uncomment and configure:
# Get your API key from: https://openrouter.ai/keys
# OPENAI_API_KEY=your-openrouter-api-key-here
# OPENAI_BASE_URL=https://openrouter.ai/api/v1
# OPENAI_MODEL=meta-llama/llama-3.1-8b-instruct  # or any supported model

# ============================================================================
# Other OpenAI-Compatible Providers
# ============================================================================
# The system works with any OpenAI-compatible API
# Just set the appropriate base_url and api_key:
# OPENAI_API_KEY=your-api-key
# OPENAI_BASE_URL=https://your-provider-url/v1
# OPENAI_MODEL=your-model-name

# ============================================================================
# Global AI Parameters
# ============================================================================
# Temperature: Controls randomness (0.0 = deterministic, 2.0 = very random)
# OPENAI_TEMPERATURE=0.7

# Max Tokens: Maximum length of generated responses
# OPENAI_MAX_TOKENS=1000

# ============================================================================
# Per-Character Configuration
# ============================================================================
# Each character can have individual AI settings in their JSON file:
# {
#   "name": "Character Name",
#   "ai_config": {
#     "enabled": true,
#     "model": "gpt-4",
#     "temperature": 0.9,
#     "system_prompt": "You are a wise wizard...",
#     "max_tokens": 1500
#   }
# }
